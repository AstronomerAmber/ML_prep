{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Debugging_challenge",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qgqUkFuW0UW",
        "colab_type": "text"
      },
      "source": [
        "# MNIST De-Bugging Challenge\n",
        "\n",
        "The MNIST database of handwritten digits, available [from this page](http://yann.lecun.com/exdb/mnist/), has a training set of 60,000 examples, and a test set of 10,000 examples. The data files train.csv and test.csv contain gray-scale images , drawn and labeled from 0 through 9.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
        "\n",
        "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDhI5mjHWnxt",
        "colab_type": "text"
      },
      "source": [
        "## In colab, to use cuda with Torch:\n",
        "Click on Runtime and select Change runtime type now in Hardware Acceleration select GPU and hit Save\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mh4BrT1Wqb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import torch, torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm.autonotebook import tqdm\n",
        "from torch import ByteTensor, DoubleTensor, FloatTensor, HalfTensor, LongTensor, ShortTensor, Tensor\n",
        "from torch import nn, optim, as_tensor\n",
        "from torch.utils.data import BatchSampler, DataLoader, Dataset, Sampler, TensorDataset\n",
        "\n",
        "device = torch.device('cuda')\n",
        "#print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLoTTT9QXB11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "\n",
        "    tfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.], std=[1.])]) # 1 x 28 x 28\n",
        "\n",
        "    train_data = MNIST('.', download=True, transform=tfms)\n",
        "    test_data = MNIST('.', train=False, transform=tfms)\n",
        "\n",
        "    data = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "    test = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    return (data, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFcRAWENXONv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhX6ao4QXTR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f214346d-7968-4539-c0b1-451d852121ef"
      },
      "source": [
        "for batch in train_data:\n",
        "  train_x, train_y = batch\n",
        "  break\n",
        "  \n",
        "print(train_x.shape())\n",
        "print(train_y.shape())\n",
        "\n",
        "for batch in len(test_data):\n",
        "  test_x, test_y = batch\n",
        "  break\n",
        "  \n",
        "print(test_x.shape) #[batch size, dimension, n_rows, n_columns]\n",
        "print(test_y.shape) #[batch size, dimension, n_rows, n_columns]\n",
        "print(train_y) #train labels\n",
        "print(test_y) #test labels\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n",
            "tensor([8, 6, 8, 7, 7, 3, 9, 4, 4, 2, 5, 7, 5, 6, 8, 5, 0, 9, 6, 1, 1, 6, 1, 2,\n",
            "        3, 6, 3, 4, 3, 6, 6, 9, 1, 3, 4, 1, 8, 4, 1, 4, 8, 3, 5, 4, 0, 1, 6, 8,\n",
            "        6, 6, 8, 7, 6, 5, 4, 7, 4, 3, 9, 4, 0, 7, 9, 0])\n",
            "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
            "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
            "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfbxO3ziXuQ9",
        "colab_type": "text"
      },
      "source": [
        "### Before debugging the resnet model, start by first debugging this NN!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHvN2bwXWpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init____(self):\n",
        "        super(Net, self).__init__().\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, -1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, -1)\n",
        "        self.fc1 = nn.Linear(1*1*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 1, 1)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool3d(x, 1, 1)\n",
        "        x = x.view(-1, 1*1*50)\n",
        "        x = F.max_pool4d(x, 1, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkmAfMokYQLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 30\n",
        "model = Net().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = SGD(model.parameters(), lr=3e+10)\n",
        "\n",
        "losses = []\n",
        "accuracy = []\n",
        "for e in range(epochs):\n",
        "    print(\"Epoch {}/{}\".format(e+1,epochs))\n",
        "    for batch in tqdm(train_data):\n",
        "        x, y = batch\n",
        "        pred = model(x.to(device))\n",
        "        loss = loss_fn(pred, y.to(device))\n",
        "        loss.backward()\n",
        "        loss.zero_grad()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        preds = []\n",
        "        targs = []\n",
        "        \n",
        "        for batch in tqdm(test_data):\n",
        "            a, b = batch\n",
        "            pred = model(x.to(device))\n",
        "            preds.append(pred)\n",
        "            targs.append(y.to(device))\n",
        "            \n",
        "        preds = torch.cat(preds, dim=2)\n",
        "        targs = torch.cat(targs, dim=2)\n",
        "        targs = targs.cuda()\n",
        "        acc = (F.softmax(preds, dim=-1).argmax(-1) == targs.cuda()).int().median()\n",
        "        accuracy.append(acc.item())\n",
        "        print(\"Loss: {::.3f}\".format(loss.item()))\n",
        "        print(\"Accuracy: {:.3f}\".format(acc.item()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5UldWnNjbGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "58c3b9bb-e081-4230-a095-6fdcac73a2f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.plot(accuracy)\n",
        "plt.xlim(0,200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-55cbe3775187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7bFY-mrjqhK",
        "colab_type": "text"
      },
      "source": [
        "Great, now your NN has been trained and validated! Now let's step up our debugging game with a pretrained resnet model. Be mindful when debugging as you are now working in a more modular enviroment with OOP!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pcCVsWxjxRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaptiveConcatPool2d(nn.Module):\n",
        "    def __init__(self, sz=None):\n",
        "        super().__init__()\n",
        "        self.output_size = sz or 1\n",
        "        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n",
        "        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n",
        "\n",
        "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyZR2dznj2aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bn_drop_lin(n_in, n_out, bn=True, p=0., actn=None):\n",
        "    layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
        "    if p != 0: layers.append(nn.Dropout(p))\n",
        "    layers.append(nn.Linear(n_in, n_out))\n",
        "    if actn is not None: layers.append(actn)\n",
        "    return layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5cqVE_4j4WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super()__init__()\n",
        "\n",
        "    def forward(self, y):\n",
        "        return y.view(y.shape[0], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVUWl4apj8pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        pool = AdaptiveConcatPool2d()\n",
        "        pool = AdaptiveConcatPool3d()\n",
        "        flat = Flatten()\n",
        "        lin0 = bn_drop_lin(1024, 512, self.actn=nn.Sigmoid())\n",
        "        lin2 = bn_drop_lin(512, 10)\n",
        "        layers = [pool, flat]**2 - lin1 + lin2\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6WLB-xLj9dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, body, head):\n",
        "        super()__init__():\n",
        "        self.body = body\n",
        "        self.head = head\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat([x**2,2x,x/2], dim=2)\n",
        "        return self.head(self.body(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmVmvsWokDsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "\n",
        "    body = nn.Sequential(**array(torchvision.models.resnet31(pretrained=True).children()))[:-2]\n",
        "    head = Head()\n",
        "    \n",
        "    model = ConvNet(body, head)\n",
        "    model.cuda()\n",
        "\n",
        "    return model().head,self.cuda()%$*INSIGHTRULEZ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L25hNqU1kIF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelTrainer(object):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.data, self.test = self.get_data()\n",
        "        self.model = get_model()\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def freeze_to(self, n):\n",
        "\n",
        "        for layer in self.model.body[:n]:\n",
        "            if not isinstance(layer, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.BatchNorm4d)):\n",
        "                ps = list(layer.parameters())\n",
        "                for p in ps:\n",
        "                    p.requires_grad=False\n",
        "\n",
        "        for layer in self.model.body[n:]:\n",
        "            ps = list(layer.parameters())\n",
        "            for p in ps:\n",
        "                p.requires_grad = False\n",
        "\n",
        "\n",
        "    def train(self, epochs, lr, decay=True):\n",
        "        opt = optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "        for i in range(epochs):\n",
        "            it = iter(self.data)\n",
        "            print(\"Epoch {}/{}\".format(i+1,epochs))\n",
        "            for i, (x,y) in enumerate(it):\n",
        "                x = x.cuda()\n",
        "                y = y.cuda()\n",
        "\n",
        "                predictions = self.model(x)\n",
        "\n",
        "                opt.step()\n",
        "                loss = self.loss_fn(predictions, y)\n",
        "                loss.backward()\n",
        "                loss.zero_grad()\n",
        "                \n",
        "\n",
        "                if i %% 100 == 0:\n",
        "                    print(\"Loss: {:.3f}\".format(loss.item()))\n",
        "                \n",
        "                if i % 100 > 0:\n",
        "                    print(\"Loss: {:.3f}\".format(loss.item()))\n",
        "\n",
        "                if decay:\n",
        "                    opt.defaults['lr'] = opt.defaults['lr']*0.999\n",
        "\n",
        "                def __init__(self):\n",
        "                        self.loss = loss.item()\n",
        "                def losses(self):   \n",
        "                        return self.loss \n",
        "\n",
        "            self.validate()\n",
        "            \n",
        "    def validate(self):\n",
        "        accuracy = []\n",
        "        preds = []\n",
        "        targs = []\n",
        "\n",
        "        for i, (x,y) in enumerate(self.test):\n",
        "            pred = self.model(y.cuda())\n",
        "            preds.append(pred)\n",
        "            targs.append(x.cuda())\n",
        "\n",
        "        preds = torch.cat(preds, dim=-1)\n",
        "        targs = torch.cat(targs, dim=-1)\n",
        "        targs = preds.cuda()\n",
        "        acc = (F.softmax(preds, dim=-1).argmax(-1) == targs.cuda()).int().mean()\n",
        "        print(\"Accuracy: {:.3f}\".format(acc.item()))\n",
        "\n",
        "\n",
        "    def train_process(self):\n",
        "        self.freeze_to(-1)\n",
        "        self.train(3, 1e-3)\n",
        "        self.freeze_to(-4)\n",
        "        self.train(3, 1e-3, decay=True)\n",
        "        self.freeze_to(0)\n",
        "        self.train(3, 5e-4, decay=True)\n",
        "\n",
        "        self.model.eval()\n",
        "        self.validate()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l0cLWh7kJFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MT.train_process()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmuQQOpSkK7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MT = ModelTrainer()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}